
## 没有优化之前

1、判断是否登录成功

2、判断商品库存 (未优化前查询数据库)

3、判断是否已经秒杀到了（查询的是redis缓存）

4、秒杀执行：如果秒杀到，减库存  下订单（创建一个订单，以及秒杀订单）  写入秒杀订单(在一个事务当中)

小的优化：

1、防止超卖，加数据库的更新判断，大于零才可以

2、针对防止多个用户重复购买  把用户id设置为唯一索引，这样在秒杀订单当中无法两次出现更新，无法重复购买

瓶颈是在于数据库的访问多次，在实行秒杀过程当中，要多次访问数据库，在秒杀订单和订单（更加详细的信息）插入数据，以及改变商品list库存等信息。

使用JMeter进行压力测试，5000个线程进行10次重复的秒杀过程的访问，QPS大概是1300


## 优化之后
优化思路

重点我们是要减少对数据库的访问

1、系统初始化时，将秒杀商品库存加载到Redis中

​	系统初始化的时候，直接将商品id和库存数量放入到redis中，同时这只库存标识我们的类实现InitializingBean接口，重写afterPropertiesSet方法，将要秒杀的商品库存数量，放入redis中。

2、秒杀判断的初始条件

- 收到请求，首先先访问库存标识（库存大于0为false,否则为true），看秒杀商品是否卖完，以减少对Redis的不必要访问。每一种参与秒杀活动的商品都在内存里用HashMap设置了一个标识，标识某个商品id商品是否卖完了。内存标识设置以及每种参与秒杀商品的库存存入redis是在系统启动时做的；
- 如果内存标识中这个商品没有卖完，则要看用户是否**重复秒杀**，规则是一个用户id对于某个商品id的商品只能秒杀一件。判断该用户有没有秒杀过这件商品，**秒杀记录也保存在redis缓存中**；如果判断秒杀过则返回提示，如果没有秒杀过，继续
- 库存不足时，直接返回秒杀失败，后续的大并发就不用直接访问数据库。有库存的时候，当秒杀请求过来的时候，不走mysql，直接去redis中判断库存的数量。系统加载时redis中保存了各商品对应的库存，这里用到**redis**的原子操作**的方法decr，将对应商品的库存减1，此时数据库时的库存还没有减，因此是**预减库存；后续的秒杀订单完成（数据库减库存，生成订单）是通过消息队列来异步完成的。

3、消息队列异步处理秒杀请求

- 正确地预减库存后，然后就要真正操作数据库了，数据库一般是性能瓶颈，比较耗时。

- 因此决定用**异步方式**处理。对于每一条**秒杀请求存入消息队列RabbitMQ**中，消息体中要包含**哪个用户（用户id)秒杀哪个商品(商品id)的信息**，这里是封装了一个消息体类。
- ==这样一个秒杀请求就进入了消息队列，但是完整的秒杀还没有完成，真正的秒杀请求的完成得要持久化到数据库，生成订单，减了数据库的库存才能算数，这时在客户端显示的一般是**排队中**==，比如以前在抢购小米手机时，我就看到这样的展示，过一会再刷新页面就显示没抢到；

4、

- 消息队列处理秒杀请求，先从消息体中解析出用户id和商品id，**查数据库看这个商品是否卖完了**，**查数据库看该用户对于这个商品是否有过秒杀记录**；

- **数据库减库存，数据库生成订单**，这两项持久化地写数据库操作放在同一个事务中，要么都执行成功，要么都失败。

- 并**把秒杀记录对象**，包括秒杀单号、订单号、用户id、商品id，**存入**redis中**。**

- 如果数据库减库存失败，表明商品卖完了，则要在redis中设置该商品已卖完的标识**。**也是数据一致性的保证问题

  

5、

- 异步发起秒杀请求，秒杀请求的处理逻辑最后也只是把这条请求放入消息队列，并不能返回是否秒杀成功的结果。

- 因此，当秒杀请求正确响应后，即请求放入消息队列后，需要另外一个请求去**轮询秒杀结果**，秒杀成功的标志是生成秒杀订单，并把秒杀订单对象放入redis中。

- 所以轮询秒杀结果，只用去轮询redis中是否有对应于该用户的该商品的秒杀订单对象，如果有，则表明秒杀成功，并在前台给出提示。











 1.   **如何解决库存的超卖问题？**

卖超原因：

（1）一个用户同时发出了多个请求，如果库存足够，没加限制，用户就可以下多个订单。

（2）减库存的sql上没有加库存数量的判断，并发的时候也会导致把库存减成负数。

解决办法：

（1）：在后端的秒杀表中，对user_id和goods_id加唯一索引，确保一个用户对一个商品绝对不会生成两个订单。

（2）：我们的减库存的sql上应该加上库存数量的判断

==数据库自身是有行级锁的，每次减库存的时候判断count>0，它实际上是串行的执行update的，因此绝对不会卖超！==



 **2.**  **如何解决少卖问题—Redis预减成功而DB扣库存失败？**

前面的方案中会出现一个少卖的问题。Redis在预减库存的时候，在初始化的时候就放置库存的大小，==redis的原子减操作保证了多少库存就会减多少，也就会在消息队列中放多少。==

现在考虑两种情况：

1）数据库那边出现非库存原因比如网络等造成减库存失败，而这时redis已经减了。

2）万一一个用户发出多个请求，而且这些请求恰巧比别的请求更早到达服务器，如果库存足够，redis就会减多次，redis提前进入卖空状态，并拒绝,但是会出现这个一个用户没有完成重复下单的时候（没有触发这个机制）Redis的库存减没了，直接拒绝了其他的用户请求，但是数据库持久化有保护机制，一个用户只能秒杀一个。不过这两种情况出现的概率都是非常低的。

两种情况都会出现少卖的问题，实际上也是**缓存和数据库出现不一致的问题**！

但是我们不是非得解决不一致的问题，本身使用缓存就难以保证强一致性：

在redis中设置库存比真实库存多一些，目的本来就是进行做缓存并发。

**3.**  **秒杀过程中怎么保证** **redis缓存和数据库的一致性？**

在其他一般读大于写的场景，一般处理的**原则**是：**缓存只做失效，不做更新。**

采用Cache-Aside pattern：

**失效**：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。

**更新**：先把数据存到数据库中，成功后，再让缓存失效。

 **4.** **Redis****中的库存如何与DB中的库存保持一致？**

Redis中的数量不是库存，它的作用仅仅时候只是为了阻挡多余的请求透传到db，起到一个保护DB的作用。因为秒杀商品的数量是有限的，比如只有10个，让1万个请求去访问DB是没有意义的，因为最多只有10个请求会下单成功，剩余的9990个请求都是无效的，是可以不用去访问db而直接失败的。

因此，这是一个伪问题，我们是不需要保持一致的。



针对单个商品，有10w+的库存，怎么优化Redis？

> 可以使用多个相互独立的Redis集群。
>
> 比如10w个库存，10个Redis集群，一个集群分1w。
>
> 存在的问题：某个集群卖完了，但实际其他集群还有，不均衡，可以
>
> 配合nginx的**最少访问**负载策略，能很大程度解决这个问题。



如果库存为N，**其实Redis不应该放N，而应该是2N、3N等**。

因为放N，若有X条异常消息，无法正常消费

- 会出现少卖：有库存，买不到
- 如果回补库存，则应该设计内存标识的重新开放。



对Redis库存进行补充后（异常或退款），如何反馈到内存标记

> 上面已经说了，已经放X倍的N，来避免这种情况，就直接也不需要进行弄这个了。
>
> 当然，该问题的答案是：
>
> 1. 单机环境下，把HashMap的范围改为public，补充库存后，直接重置HashMap为true。
>
> 2. 集群环境下，就把补充的消息推送到MQ，各个节点进行监听，修改本地的HashMap。或者直接依靠集群的同步机制完成。
>
> 3. 直接依靠定时任务，根据[redis]()的库存定时更新HashMap的值。
>
>    这种方法缺点也很明显，定时间隔长了，实时性不强。间隔短，性能低





**如何防刷？**

IP限流+验证码



**为什么要进行秒杀接口暴露的控制或者说进行秒杀接口的隐藏？**

- 现实中有的用户回通过浏览器插件提前知道秒杀接口，填入参数和地址来实现自动秒杀，这对于其他用户来说是不公平的。

- 所以我们可以控制让用户在没有到秒杀时间的时候不能获取到秒杀地址，只返回秒杀的开始时间。

- 当到秒杀时间的时候才返回秒杀地址即seckill_id以及根据seckill_id和salt加密的MD5，前端再次拿着seckill_id和MD5才能执行秒杀。假如用户在秒杀开始前猜测到秒杀地址seckill_id去请求秒杀，也是不会成功的，因为它拿不到需要验证的MD5。这里的MD5相当于是用户进行秒杀的凭证。

  ![img](https://images2018.cnblogs.com/blog/996415/201807/996415-20180722210205118-1212925857.png)

**数据库表有哪些**

商品表、商品表订单表、秒杀商品表、秒杀商品订单表

**热key问题如何解决？**

redis集群+本地缓存+限流+key加随机值分布在多个实例中

###### 热key的危害

- 流量集中，达到服务器处理上限（`CPU`、网络 `IO` 等）；

- 会影响在同一个 `Redis` 实例上其他 `Key` 的读写请求操作；

- 热 `Key` 请求落到同一个 `Redis` 实例上，无法通过扩容解决；

- 大量 `Redis` 请求失败，查询操作可能打到数据库，拖垮数据库，导致整个服务不可用。

  

###### 发现热key方法

-   业务经验，预估热 Key，比如业务需要进行一场商品秒杀活动，秒杀商品信息和数量一般都会缓存到 `Redis` 中，这种场景极有可能出现热 `Key` 问题的。
- 客户端收集：对Redis客户端工具进行封装，在发送请求前进行收集采集，同时定时把收集到的数据上报到统一的服务进行聚合计算
- 代理端收集：请求都经过 `Proxy`（代理）的话，可以考虑改动 `Proxy` 代码进行收集，思路与客户端基本类似。

###### redis解决热key方式

- 利用 `redis-cli --hotkeys` 获取当前 `keyspace` 的热点 `key`

- 通过 `redis-cli monitor` 抓取数据，同时结合一些现成的分析工具，比如 [redis-faina](https://github.com/facebookarchive/redis-faina)，统计出热 Key。

###### 如何解决热key

- 增加 Redis 实例复本数量

  对于出现热 `Key` 的 `Redis` 实例，我们可以通过水平扩容增加副本数量，将读请求的压力分担到不同副本节点上。

- 本地缓存
  
  出现热 `Key` 以后，把热 `Key` 加载到系统的 `JVM` 中。后续针对这些热 `Key` 的请求，会直接从 `JVM` 中获取，而不会走到 `Redis` 层，注意本地缓存和redis集群数据一致性问题，可以用hashmap
  
- 热key备份
热key备份，比如key，备份为key1,key2……keyN，同样的数据N个备份，N个备份分布到不同分片，访问时可随机访问N个备份中的一个,进一步分担读流量

**6、缓存和数据库数据一致性如何保证？**

秒杀项目不用保证，其他项目就用延时双删或者先更新数据再是缓存失效，为防缓存失效这一信息丢失，可用消息队确保。



**7、消息队列的作用？**

如何保证消息的不丢失？异步削峰；发送方开启confirm+消息队列持久化+消费方关闭自动ACK,确保消费成功之后自动调用API进行确认。



**4. 分布式Session是怎么实现的**

- 用户登录后==生成随机字符串==，并==向cookie中写入此字符串==。
- 在Redis中记录此字符串和用户信息的映射
- 当用户再次访问网页时，取出cookie中对应字段值，根据此字段值访问Redis得到用户相关信息

**6.如何解决重复下单？**

- 执行减库存下订单逻辑前，判断是否在订单表中含有用户秒杀此商品的记录
- 利用唯一索引，在订单表中创建user_id和good_id组成的唯一索引，这样在重复插入数据的时候会插入失败，之前的减库存操作在事务中也会回滚。

**9、项目可以改进的地方**

- 限流做的不够完善，目前只对单个用户对于某个商品的访问做了限流，没有对整体的流量做限流，比如不法分子有非常多的账号，同时对一个商品发起请求可能造成我们的服务不可用。
- 在这个项目中是对库存和静态数据进行了预热，但是实际中有可能某个商品可能一时间快速爆火，如果没有对这些是商品数据进行预热可能会使服务宕掉，需要快速发现热点数据的发现与隔离
- 没有考虑redis穿透的情况处理方案

**库存预减用的是哪个redis方法？**

- 使用Jedis封装相关方法，减库存使用decr方法，是原子性的

**缓存和数据库数据一致性如何保证？**

- 对于库存数据不需要保证，缓存中的库存只为了过滤请求，即使多放进来一些请求我们也可以在数据库层面保证不超卖。
- 对于商品信息的静态数据也不需要保证数据一致性，因为不会变

**如何防刷？**

- 对一个商品秒杀时Redis会记录一个用户对一个商品的秒杀按钮的点击次数，如果用户对按钮点击次数超过5次直接返回多次请求提示
- 但是并没有对所有流量进行限流，有非常多的账号，同时对一个商品发起请求可能造成我们的服务不可用。

**消息队列的作用？**

- 削峰，减少同一时刻并发量
- 入队后直接返回用户排队中消息，提高用户体验

13. 假如减了库存但用户没有支付，怎么将库存还原继续进行抢购

- 订单超时未支付则删除订单，增加库存数量，恢复Redis缓存和本地缓存的数量
- 但是对于秒杀项目之所以采用下订单减库存而不是付款减库存不就是因为秒杀商品秒到就是赚到大概率不会不付款嘛。另外即使不付款，那就不会发货，只会少卖不会超卖对于商户也不会有什么损失吧。

**验证码的作用：**

- 防止利用机器人等手段防止非目标用户参与秒杀；


- 减少单位时间内的请求数量。对于一个秒杀商品，在开始秒杀后肯定会有许多用户参与秒杀，那么在开始秒杀的时候，用户请求数量是巨大，从而对服务器产生较大的压力，而通过验证码的方式就可以==有效地将集中式的请求分散，从而达到削减请求峰值的目的。==

**验证码的具体的过程和意义**

- 对于数学公式的生成，生成3个0到9之间的随机数，然后在生成一个字符数组，用于存放 + - * （加减乘）三个数学运算符，随机选中两个字符，然后对其进行拼接 成一个字符串，数+运算符+数+运算符+数，返回这个字符串。
- 利用scriptEngine类，调用JavaScript的eval() 方法，计算这个字符串公式的值，将这个值保存到redis上面去（用户下次发送验证请求的时候，直接去缓存里面取出并验证即可）
- 在前端进行设置 ，前端得到这个验证码图片，显示该验证码，然后用户需要输入验证码将这个验证码作为参数，与==获取秒杀地址请求一起传输给后端==（==校验的操作在获取秒杀地址之前==），后端接收到参数，进行验证码比对，缓存中取出该验证码进行校验。==如果不通过，不生成秒杀接口地址，直接返回验证码错误信息。==

**秒杀接口隐藏的具体过程**

- 用户在提交获取秒杀地址的请求之前，需要将==goodsId==和==验证码==结果一同提交到服务端，服务器通过@RequestParam参数获取goodsId和verifyCode，然后检验验证码是否正确，==如果正确，则返回秒杀地址给客户端，客户端得到秒杀地址后，拼接秒杀地址然后异步地向这个地址发出请求获取秒杀结果==，这样就完成了秒杀接口地址的隐藏。
- 验证成功才返回随机生成的秒杀地址，不成功则返回非法请求，通过这样一种双重验证的方式，就可以防止用户使用不合理的手段参与秒杀，引入验证码有效地防止了这一点，因为验证码的输入需要用户真正参与进来。
- 返回的秒杀path 是通过UUID生成，并且MD5加密，并且设置到redis缓存，key根据用户id和商品id 生成，所以每个用户获取到的秒杀地址不一样，每个用户的秒杀地址变量path与redis缓存中对比

**页面缓存、URL缓存、对象缓存的作用解释一下？**

- 由于并发瓶颈在数据库，想办法如何减少对数据库的访问，所以加若干缓存来提高，通过各种粒度的缓存，最大粒度页面缓存到最小粒度的对象级缓存。



**页面缓存**
- **页面缓存**：当访问页面的时候，先缓存里面取，如果找到就可以直接返回给客户端，如果说没有，那我们手动来渲染这个模板，渲染出来以后，就把结果输出给客户端。同时把这个结果缓存到像redis缓存里面来。
- 比如说商品列表页，使用页面缓存技术，如果从Redis中取到就返回html，取不到的话，利用ThymeleafViewResolver的getTemplateEngine().process和我们获取到的数据，渲染模板，并且在返回到前端之前保存至Redis里面，之后再来获取的时候，只要缓存里面存的goods_list页面的html还没有过期，那么直接返回给前端即可。
- **页面缓存时间，也不会很长，防止数据的时效性很低。但是可以防止短时间大并发访问。**



**URL缓存：**

- 当进行redis缓存时，在页面缓存基础上加入了路径上的参数（如goodsId）
  这里的url缓存和页面缓存相差不大，针对不同的详情页显示不同缓存页面，对不同的url进行缓存。
- 项目当中使用的是不同商品的详情页进行了URL缓存

**对象缓存：**
对象缓存：相比页面缓存是更细粒度缓存。在实际项目中， 不会大规模使用页面缓存，==对象缓存就是当用到用户数据的时候，可以从缓存中取出==，对象级缓存是最小的粒度（其一般不存在过期时间，因为只要对象不变化，其都是永久的），它可以拿到key直接对应一个对象。MiaoshaUserService里面增加getById方法，先去取缓存，如果缓存中拿不到，那么就去取数据库，然后再设置到缓存中去：

![img](https://images2018.cnblogs.com/blog/996415/201807/996415-20180722212950465-854237179.png)

![img](https://images2018.cnblogs.com/blog/996415/201807/996415-20180722213057245-1799070767.png)